{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfcR2r9qASVR"
      },
      "outputs": [],
      "source": [
        "import scipy.misc\n",
        "import random\n",
        "import imageio\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python.tools import optimize_for_inference_lib\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K\n",
        "import keras.optimizers as optimizers\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.models import load_model\n",
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation, BatchNormalization\n",
        "from keras.optimizers import SGD,RMSprop,Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs = []\n",
        "ys = []\n",
        "def Load_data_malignant():\n",
        "    path =\"/content/drive/MyDrive/DATASET/malignant\"\n",
        "    x_out = []\n",
        "    y_out = []\n",
        "    for i in range(1, 1500):\n",
        "        img = imageio.imread(path +'/' + str(i) + '.jpg')\n",
        "        lab = 1\n",
        "        x_out.append(img)\n",
        "        y_out.append(lab)\n",
        "    return x_out, y_out"
      ],
      "metadata": {
        "id": "Vd8J9xQvCChz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Load_data_benign():\n",
        "    path =\"/content/drive/MyDrive/DATASET/benign\"\n",
        "    x_out = []\n",
        "    y_out = []\n",
        "    for i in range(1, 1800):\n",
        "        img = imageio.imread(path +'/' + str(i) + '.jpg')\n",
        "        lab = 0\n",
        "        x_out.append(img)\n",
        "        y_out.append(lab)\n",
        "    return x_out, y_out"
      ],
      "metadata": {
        "id": "lXBd6OG8CCeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_0, y_0 = Load_data_benign()"
      ],
      "metadata": {
        "id": "8ifWmfudCCbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_1, y_1 = Load_data_malignant()"
      ],
      "metadata": {
        "id": "Rk9AeqgtCCZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_0 = np.array(x_0)\n",
        "y_0 = np.array(y_0)\n",
        "\n",
        "x_1 = np.array(x_1)\n",
        "y_1 = np.array(y_1)"
      ],
      "metadata": {
        "id": "SRPf_F8lCCWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "x=np.concatenate((x_0, x_1), axis=0)\n",
        "y=np.concatenate((y_0, y_1), axis=0)\n",
        "\n",
        "y = np_utils.to_categorical(y, num_classes)"
      ],
      "metadata": {
        "id": "SLR_EOmACCSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_Test, y_train, y_Test = train_test_split(x, y, test_size=0.3, random_state=5,stratify=y)"
      ],
      "metadata": {
        "id": "bhj7IP_mCCPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nClasses = 2\n",
        "\n",
        "def createModel():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(15, (3, 3), padding='valid', activation='relu', input_shape=(224,224,3)))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Conv2D(15, (3, 3), padding='same',activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(15, (3, 3), padding='same',activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(15, (3, 3), padding='valid', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(nClasses, activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "R3XIw8b9CCMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = None\n",
        "model1 = createModel()\n",
        "batch_size = 40\n",
        "epochs = 150\n",
        "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99, epsilon=None, decay=0)\n",
        "model1.compile(loss='binary_crossentropy', optimizer=opt,metrics = ['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "dW8GW9nXCepf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model1.fit(x_train, y_train, epochs=150,batch_size = batch_size,validation_data= (x_Test, y_Test), shuffle=True)"
      ],
      "metadata": {
        "id": "YEAn2aTBCemK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['categorical_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kfUhfjKICeit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aMdoAGeHCef2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = model.predict(x_Test, batch_size=32, verbose=1)\n",
        "predicted = np.argmax(pred, axis=1)\n",
        "report = classification_report(np.argmax(y_Test, axis=1), predicted)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "Qm6vpDAQCecs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}